{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import utils\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = []\n",
    "unsplit = []\n",
    "labels = []\n",
    "\n",
    "with open('data/smos_data_porter.txt', newline='') as datafile:\n",
    "    data_reader = csv.reader(datafile, delimiter='\\n')\n",
    "    \n",
    "    for row in data_reader:\n",
    "        strings.append(row[0].split())\n",
    "        unsplit.append(row[0])\n",
    "        \n",
    "with open('data/smos_labels.txt', newline='') as datafile:\n",
    "    data_reader = csv.reader(datafile, delimiter='\\n')\n",
    "    \n",
    "    for row in data_reader:\n",
    "        labels.append(int(row[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4556\n"
     ]
    }
   ],
   "source": [
    "print(len(strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, index = {}, 1 # start indexing from 1\n",
    "vocab['<pad>'] = 0 # add a padding token \n",
    "\n",
    "for row in strings:\n",
    "    for token in row:\n",
    "        if token not in vocab: \n",
    "            vocab[token] = index\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_vocab = {index: token for token, index in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inverse_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391.4074074074074\n"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "\n",
    "for enc in encoded:\n",
    "    lengths.append(len(enc))\n",
    "    \n",
    "print(sum(enc) / len(enc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded = []\n",
    "encoded = np.zeros((4556, 390))\n",
    "\n",
    "for i,row in enumerate(strings):\n",
    "    # print(row)\n",
    "    enc = np.array([vocab[token] for token in row])\n",
    "    # print(np.shape(enc))\n",
    "    # print(enc)\n",
    "    if len(enc) < 390:\n",
    "        enc = np.append(enc, np.zeros(390-len(enc)))\n",
    "    #print(enc)\n",
    "    np.random.shuffle(enc)\n",
    "    # print(np.shape(enc))\n",
    "    # enc.reshape((390, 1))\n",
    "    # print(np.shape(enc))\n",
    "    #print(enc)\n",
    "    enc = enc[:390]\n",
    "    enc = enc.reshape(1, -1)\n",
    "    #print(enc)\n",
    "    encoded[i] = enc\n",
    "    # encoded.append([vocab[token] for token in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1)\n",
    "pca.fit(encoded)\n",
    "compressed = pca.transform(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = SMOTE(sampling_strategy=.75).fit_resample(compressed, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded = pca.inverse_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390\n"
     ]
    }
   ],
   "source": [
    "print(len(expanded[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "for row in expanded:\n",
    "    new_data.append([inverse_vocab[int(value)] for value in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project_2",
   "language": "python",
   "name": "project_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
